# LibreChat configuration file
# See: https://docs.librechat.ai/install/configuration/custom_config.html

version: 1.2.8
cache: true

# UI Interface settings
interface:
  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: true
  prompts: true
  bookmarks: true
  multiConvo: true
  agents: true

registration:
  socialLogins: ["openid"]
  allowedDomains:
  - "amendllc.com"
 
memory:
  disabled: false
  validKeys:
    - "user_preferences"
    - "learned_facts"
    - "personal_information"
    - "skills"
    - "interests"
  tokenLimit: 3000
  personalize: true
  messageWindowSize: 8
  agent:
    provider: "AMEND_AI-Global"
    model: "azure/gpt-4.1-mini"
    instructions: |
      Store memory using only the specified validKeys. For user_preferences: save 
      explicitly stated preferences about communication style, topics of interest, 
      or workflow preferences. Don't save details about the specific conversation. For conversation_context: save important facts or 
      ongoing projects mentioned. For learned_facts: save objective information 
      about the user. For personal_information: save only what the user explicitly 
      shares about themselves. Delete outdated or incorrect information promptly.
    model_parameters:
      temperature: 0.2
      max_tokens: 2000
      top_p: 0.8
      frequency_penalty: 0.1

# Web Search configuration
webSearch:
  # Search Provider Configuration
  serperApiKey: "${SERPER_API_KEY}"
  searchProvider: "serper" # Options: "serper", "searxng"

  # Scraper Configuration
  firecrawlApiKey: "${FIRECRAWL_API_KEY}"
  firecrawlApiUrl: "${FIRECRAWL_API_URL}"
  scraperType: "firecrawl" # Options: "firecrawl", "serper"

  # Reranker Configuration
  jinaApiKey: "${JINA_API_KEY}"
  cohereApiKey: "${COHERE_API_KEY}"
  rerankerType: "jina" # Options: "jina", "cohere"

  # General Settings
  scraperTimeout: 7500 # Timeout in milliseconds for scraper requests (default: 7500)
  safeSearch: 1 # Options: 0 (OFF), 1 (MODERATE - default), 2 (STRICT)

# File upload and output configuration
fileConfig:
  endpoints:
    default:
      totalSizeLimit: 20  # Max total upload per request (MB)
    LiteLLM:
      fileLimit: 5        # Max 5 files per request
      fileSizeLimit: 10   # Max 10MB per file
      supportedMimeTypes:
        - "image/.*"
        - "application/pdf"
  serverFileSizeLimit: 100  # Max file size (MB) for uploads to server
  avatarSizeLimit: 2        # Max avatar image size (MB)
  imageGeneration:
    percentage: 100
    px: 1024
  clientImageResize:
    enabled: false
    maxWidth: 1900
    maxHeight: 1900
    quality: 0.92

# Endpoints configuration
endpoints:
  custom:
    
    #AMEND_AI-Global: Available to all users
    - name: "AMEND_AI-Global"
      apiKey: "${LITELLM_DEFAULT_APIKEY}"
      baseURL: "${LITELLM_URL}"
      models:
        default: ["azure/gpt-4.1-mini"]
        fetch: true
      titleConvo: true
      titleModel: "azure/gpt-4.1-mini"
      summarize: true
      summaryModel: "azure/gpt-4.1-mini"
      forcePrompt: true
      userIdQuery: true
      modelDisplayLabel: "AMEND AI-Global"
    
    #Group of models with strengths in coding - unlocked with individual keys
    - name: "AMEND_AI-Coding_Models"
      apiKey: "user_provided"
      baseURL: "${LITELLM_URL}"
      models:
        default: 
        - "azure/gpt-4-1"
        - "anthropic/claude-sonnet-4-20250514"
        - "gemini/gemini-2.5-pro"
        - "gemini/gemini-2.5-flash"
        - "azure/o3-mini"
        - "azure/o4-mini"
        fetch: false
      titleConvo: true
      titleModel: "azure/gpt-4.1-mini"
      summarize: true
      summaryModel: "azure/gpt-4.1-mini"
      forcePrompt: true
      modelDisplayLabel: "AMEND AI - Coding Models"
    
    #Group of reasoning specific models - unlocked with individual keys
    - name: "AMEND_AI-Reasoning_Models"
      apiKey: "user_provided"
      baseURL: "${LITELLM_URL}"
      models:
        default: 
        - "azure/DeepSeek-R1"
        - "azure/o3-mini"
        - "azure/o4-mini"
        - "azure/o3"
        - "gemini/gemini-2.0-flash-thinking-exp"
        fetch: false
      titleConvo: true
      titleModel: "azure/gpt-4.1-mini"
      summarize: true
      summaryModel: "azure/gpt-4.1-mini"
      forcePrompt: true
      modelDisplayLabel: "AMEND AI - Reasoning Models"
    
    #Group of Larger more advanced models - unlocked with individual keys
    - name: "AMEND_AI-Advanced_Models"
      apiKey: "user_provided"
      baseURL: "${LITELLM_URL}"
      models:
        default: 
        - "azure/gpt-4-1"
        - "azure/o3"
        - "anthropic/claude-4-opus-20250514"
        - "gemini/gemini-2.5-pro"
        fetch: false
      titleConvo: true
      titleModel: "azure/gpt-4.1-mini"
      summarize: true
      summaryModel: "azure/gpt-4.1-mini"
      forcePrompt: true
      modelDisplayLabel: "AMEND AI - Advanced Models"
      
    # - name: "Portkey"
    #   apiKey: "dummy"  
    #   baseURL: "${PORTKEY_GATEWAY_URL}"
    #   headers:
    #       x-portkey-api-key: "${PORTKEY_API_KEY}"
    #       x-portkey-provider: "azure-open-ai-0369c1"
    #       # x-portkey-config: "pc-amend-706c47"
    #       # x-portkey-virtual-key: "PORTKEY_OPENAI_VIRTUAL_KEY"
    #       x-portkey-metadata: '{"_user": "{{LIBRECHAT_USER_EMAIL}}"}' # this header is to edit
    #   models:
    #       default: 
    #       - "gpt-4.1-mini"
    #       fetch: true
    #   titleConvo: true
    #   titleModel: "gpt-4.1-mini"
    #   summarize: false
    #   summaryModel: "gpt-4.1-mini"
    #   forcePrompt: false
    #   modelDisplayLabel: "Portkey:OpenAI"
    #   iconURL: https://images.crunchbase.com/image/upload/c_pad,f_auto,q_auto:eco,dpr_1/rjqy7ghvjoiu4cd1xjbf

# ocr:
#   mistralModel: "${MISTRAL_MODEL}" # should match deployment name on Azure
#   apiKey: "${OCR_API_KEY}" # arbitrary .env var reference
#   baseURL: "${OCR_BASEURL}" # hardcoded, can also be .env var reference
#   strategy: "mistral_ocr"

# `librechat.yaml`
ocr:
  mistralModel: "mistral-ocr-2503-amend"              # Should match your Azure deployment name
  apiKey: "${AZURE_MISTRAL_OCR_API_KEY}"                 # Reference to your Azure API key in .env
  baseURL: "https://mistral-ocr-2503-amend.eastus.models.ai.azure.com/v1"  # Your Azure endpoint
  strategy: "azure_mistral_ocr"                          # Use Azure strategy

mcpServers:
  
 #Firecrawl MCP Server
  firecrawl:
    command: npx
    args: ["-y", "firecrawl-mcp"]
    env:
      FIRECRAWL_API_KEY: "${FIRECRAWL_API_KEY}"
      FIRECRAWL_API_URL: "${FIRECRAWL_API_URL}"
    chatMenu: true  # Only available in agent builder

  #Searxng MCP Server
  private-web-searching-searxng:
    command: npx
    args: ["-y", "mcp-searxng"]
    env:
      SEARXNG_URL: "${SEARXNG_URL}"
    chatMenu: true  # Only available in agent builder

  #Jina MCP Server
  commercial-web-searching-jina:
    command: npx
    args: ["jina-mcp-tools"]
    env:
      JINA_API_KEY: "${JINA_API_KEY}"
    chatMenu: true  # Only available in agent builder

  platform-feedback:
    type: streamable-http
    url: https://n8n.amendllc.com/mcp/platform-feedback
    headers:
      Authorization: "Bearer ${AMEND_ASSISTANTS_MCP_BEARER}"
      X-User-Email: "{{LIBRECHAT_USER_EMAIL}}"
      X-LIBRECHAT_USER_OPENIDID: "{{LIBRECHAT_USER_OPENIDID}}"
      X-LIBRECHAT_USER_USERNAME: "{{LIBRECHAT_USER_USERNAME}}"
    When sending emails:
      - Make sure you have all the information needed and, if needed, ask for more information


  kantata-tools:
    type: streamable-http
    url: https://ktmcp.amendllc.com/mcp #for production
    #url: http://kantata-mcp.kantata-mcp.orb.local/mcp #for local testing
    headers:
      Authorization: "${KANTATA_MCP_BEARER_TOKEN}"
      x-auth-token: "{{USER_PROVIDED_TOKEN}}"
    customUserVars:
      USER_PROVIDED_TOKEN:
        title: "My Session Id"
        description: "Your Kantata OX session ID after you go through the auth process with Kantata"
    chatMenu: true

  lucid-chart-tools:
    type: streamable-http
    #url: http://localhost:3009/mcp #for production
    url: http://lucid-mcp.lucid-mcp-server.orb.local/mcp #for local testing
    headers:
      Authorization: "Bearer ${LUCIDCHART_MCP_BEARER_TOKEN}"
      x-auth-token: "{{USER_PROVIDED_TOKEN}}"
    customUserVars:
      USER_PROVIDED_TOKEN:
        title: "My Session Id"
        description: "Your Lucid session ID after you go through the auth process with Lucid"
    chatMenu: true


  #Microsoft Tools
  # microsoft-tools:
  #   command: npx
  #   args: ["-y", "@softeria/ms-365-mcp-server","--http 3000","-v"]
  #   env:
  #     # - ENABLED_TOOLS: Filter tools using regex pattern (alternative to --enabled-tools flag)
  #     MS365_MCP_FORCE_WORK_SCOPES: "true|1" #Force inclusion of work account scopes (alternative to --force-work-scopes flag)
  #     # LOG_LEVEL: "info"
  #     # SILENT: "true|1" #Disable console output
  #     MS365_MCP_CLIENT_ID: "${MS365_MCP_CLIENT_ID}" #Custom Azure app client ID (defaults to built-in app)
  #     MS365_MCP_TENANT_ID: "${MS365_MCP_TENANT_ID}" #Custom tenant ID (defaults to 'common' for multi-tenant)
  #     MS365_MCP_CLIENT_SECRET: "${MS365_MCP_CLIENT_SECRET}"
  #   chatMenu: true

  # amend-ai-assistant-tools:
  #   type: streamable-http
  #   url: https://n8n.amendllc.com/mcp/email-tools
  #   headers:
  #     Authorization: "Bearer ${AMEND_ASSISTANTS_MCP_BEARER}"
  #     X-User-Email: "{{LIBRECHAT_USER_EMAIL}}"
  #     X-LIBRECHAT_USER_OPENIDID: "{{LIBRECHAT_USER_OPENIDID}}"
  #     #X-LIBRECHAT_USER_USERNAME: "{{LIBRECHAT_USER_USERNAME}}"
  #     X-LIBRECHAT_USER_USERNAME: "integration@amendllc.com"
  #   serverInstructions: |
  #     When sending emails:
  #     - Always confirm the message to be sent, who the sender email is, and the email address the email is being sent to

# Balance settings
balance:
  enabled: true                # Enable token credit balances for users
  startBalance: 10000000          # Initial tokens credited upon registration
  autoRefillEnabled: true     # Enable automatic token refills
  refillIntervalValue: 30      # Numerical value for refill interval
  refillIntervalUnit: "days"   # Time unit for refill interval (days, hours, etc.)
  refillAmount: 10000000          # Tokens added during each refill

speech:
  speechTab:
    conversationMode: true
    advancedMode: false
    speechToText:
      engineSTT: "external"
      languageSTT: "English (US)"
      autoTranscribeAudio: true
      decibelValue: -45
      autoSendText: 0
    textToSpeech:
      engineTTS: "external"
      voice: "alloy"
      languageTTS: "en"
      automaticPlayback: true
      playbackRate: 1.0
      cacheTTS: true

  stt:
    openai:
      url: "https://litellm.amendllc.com/v1/audio/transcriptions"
      model: "azure/whisper"
      apiKey: "${LITELLM_WHISPER_KEY}"

  tts:
    openai:
      url: "https://litellm.amendllc.com/v1/audio/speech"
      apiKey: "${LITELLM_WHISPER_KEY}"
      model: "azure/tts"
      voices: ['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']