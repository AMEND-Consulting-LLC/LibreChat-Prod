# For more information, visit the documentation:
# https://www.librechat.ai/docs/configuration/librechat_yaml

version: 1.2.5

# Simple cache configuration
cache: true

# Rate limits for file uploads
rateLimits:
  fileUploads:
    ipMax: 100
    ipWindowInMinutes: 60
    userMax: 50
    userWindowInMinutes: 60

# Endpoints configuration
endpoints:
  custom:
    - name: "litellm"
      apiKey: "user_provided"
      baseURL: "http://localhost:4000"
      models:
        default: [
          "gpt-4o",
          "gpt-4-turbo",
          "gpt-4",
          "gpt-3.5-turbo",
          "claude-3-opus-20240229",
          "claude-3-sonnet-20240229",
          "claude-3-haiku-20240307",
          "gemini-pro",
          "gemini-pro-vision"
        ]
      titleConvo: true
      titleModel: "gpt-3.5-turbo"
      summarize: false
      summaryModel: "gpt-3.5-turbo"
      forcePrompt: false
      modelDisplayLabel: "LiteLLM"
      addParams: {}
      dropParams: []

# File handling strategy
fileStrategy: "local"

# Registration settings
registration:
  social:
    - "google"
    - "github"
    - "discord"

# Interface settings
interface:
  privacyPolicy:
    externalUrl: ""
    openInNewTab: false
  termsOfService:
    externalUrl: ""
    openInNewTab: false
