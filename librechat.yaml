# LibreChat configuration file
# See: https://docs.librechat.ai/install/configuration/custom_config.html

version: 1.2.8
cache: true

# UI Interface settings
interface:
  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: true
  prompts: true
  bookmarks: true
  multiConvo: true
  agents: true

registration:
  socialLogins: ["openid"]
  allowedDomains:
  - "amendllc.com"
 
memory:
  disabled: false
  validKeys:
    - "user_preferences"
    - "conversation_context" 
    - "learned_facts"
    - "personal_information"
    - "skills"
    - "interests"
    - "context"
  tokenLimit: 3000
  personalize: true
  messageWindowSize: 8
  agent:
    provider: "AMEND_AI-Global"
    model: "azure/gpt-4.1-mini"
    instructions: |
      Store memory using only the specified validKeys. For user_preferences: save 
      explicitly stated preferences about communication style, topics of interest, 
      or workflow preferences. For conversation_context: save important facts or 
      ongoing projects mentioned. For learned_facts: save objective information 
      about the user. For personal_information: save only what the user explicitly 
      shares about themselves. Delete outdated or incorrect information promptly.
    model_parameters:
      temperature: 0.2
      max_tokens: 2000
      top_p: 0.8
      frequency_penalty: 0.1

# Web Search configuration
webSearch:
  # Search Provider Configuration
  serperApiKey: "${SERPER_API_KEY}"
  searchProvider: "serper" # Options: "serper", "searxng"

  # Scraper Configuration
  firecrawlApiKey: "${FIRECRAWL_API_KEY}"
  firecrawlApiUrl: "${FIRECRAWL_API_URL}"
  scraperType: "firecrawl" # Options: "firecrawl", "serper"

  # Reranker Configuration
  jinaApiKey: "${JINA_API_KEY}"
  cohereApiKey: "${COHERE_API_KEY}"
  rerankerType: "jina" # Options: "jina", "cohere"

  # General Settings
  scraperTimeout: 7500 # Timeout in milliseconds for scraper requests (default: 7500)
  safeSearch: 1 # Options: 0 (OFF), 1 (MODERATE - default), 2 (STRICT)

# File upload and output configuration
fileConfig:
  endpoints:
    default:
      totalSizeLimit: 20  # Max total upload per request (MB)
    LiteLLM:
      fileLimit: 5        # Max 5 files per request
      fileSizeLimit: 10   # Max 10MB per file
      supportedMimeTypes:
        - "image/.*"
        - "application/pdf"
  serverFileSizeLimit: 100  # Max file size (MB) for uploads to server
  avatarSizeLimit: 2        # Max avatar image size (MB)
  imageGeneration:
    percentage: 100
    px: 1024
  clientImageResize:
    enabled: false
    maxWidth: 1900
    maxHeight: 1900
    quality: 0.92

# Endpoints configuration
endpoints:
  custom:
    
    #AMEND_AI-Global: Available to all users
    - name: "AMEND_AI-Global"
      apiKey: "${LITELLM_DEFAULT_APIKEY}"
      baseURL: "${LITELLM_URL}"
      models:
        default: ["azure/gpt-4.1-mini"]
        fetch: true
      titleConvo: true
      titleModel: "azure/gpt-4.1-mini"
      summarize: true
      summaryModel: "azure/gpt-4.1-mini"
      forcePrompt: true
      userIdQuery: true
      modelDisplayLabel: "AMEND AI-Global"
    
    #Group of models with strengths in coding - unlocked with individual keys
    - name: "AMEND_AI-Coding_Models"
      apiKey: "user_provided"
      baseURL: "${LITELLM_URL}"
      models:
        default: 
        - "azure/gpt-4-1"
        - "anthropic/claude-sonnet-4-20250514"
        - "gemini/gemini-2.5-pro"
        - "gemini/gemini-2.5-flash"
        - "azure/o3-mini"
        - "azure/o4-mini"
        fetch: false
      titleConvo: true
      titleModel: "azure/gpt-4.1-mini"
      summarize: true
      summaryModel: "azure/gpt-4.1-mini"
      forcePrompt: true
      modelDisplayLabel: "AMEND AI - Coding Models"
    
    #Group of reasoning specific models - unlocked with individual keys
    - name: "AMEND_AI-Reasoning_Models"
      apiKey: "user_provided"
      baseURL: "${LITELLM_URL}"
      models:
        default: 
        - "azure/DeepSeek-R1"
        - "azure/o3-mini"
        - "azure/o4-mini"
        - "azure/o3"
        - "gemini/gemini-2.0-flash-thinking-exp"
        fetch: false
      titleConvo: true
      titleModel: "azure/gpt-4.1-mini"
      summarize: true
      summaryModel: "azure/gpt-4.1-mini"
      forcePrompt: true
      modelDisplayLabel: "AMEND AI - Reasoning Models"
    
    #Group of Larger more advanced models - unlocked with individual keys
    - name: "AMEND_AI-Advanced_Models"
      apiKey: "user_provided"
      baseURL: "${LITELLM_URL}"
      models:
        default: 
        - azure/gpt-4-1
        - "azure/o3"
        - "anthropic/claude-4-opus-20250514"
        - "gemini/gemini-2.5-pro"
        fetch: false
      titleConvo: true
      titleModel: "azure/gpt-4.1-mini"
      summarize: true
      summaryModel: "azure/gpt-4.1-mini"
      forcePrompt: true
      modelDisplayLabel: "AMEND AI - Advanced Models"

ocr:
  mistralModel: "${MISTRAL_MODEL}" # should match deployment name on Azure
  apiKey: "${OCR_API_KEY}" # arbitrary .env var reference
  baseURL: "${OCR_BASEURL}" # hardcoded, can also be .env var reference
  strategy: "mistral_ocr"

# `librechat.yaml`
# ocr:
#   mistralModel: "mistral-ocr-2503-amend"              # Should match your Azure deployment name
#   apiKey: "${AZURE_MISTRAL_OCR_API_KEY}"                 # Reference to your Azure API key in .env
#   baseURL: "https://mistral-ocr-2503-amend.eastus.models.ai.azure.com/v1"  # Your Azure endpoint
#   strategy: "azure_mistral_ocr"                          # Use Azure strategy

mcpServers:
  
 #Firecrawl MCP Server
  firecrawl:
    command: npx
    args: ["-y", "firecrawl-mcp"]
    env:
      FIRECRAWL_API_KEY: "${FIRECRAWL_API_KEY}"
      FIRECRAWL_API_URL: "${FIRECRAWL_API_URL}"
    chatMenu: true  # Only available in agent builder

  #Searxng MCP Server
  searxngmcp:
    command: npx
    args: ["-y", "mcp-searxng"]
    env:
      SEARXNG_URL: "${SEARXNG_URL}"
    chatMenu: true  # Only available in agent builder

  #Jina MCP Server
  jina-mcp-tools:
    command: npx
    args: ["jina-mcp-tools"]
    env:
      JINA_API_KEY: "${JINA_API_KEY}"
    chatMenu: true  # Only available in agent builder

  # amend-ai-assistant-tools:
  #   type: streamable-http
  #   url: https://n8n.amendllc.com/mcp/email-tools
  #   headers:
  #     Authorization: "Bearer ${AMEND_ASSISTANTS_MCP_BEARER}"
  #     X-User-Email: "{{LIBRECHAT_USER_EMAIL}}"
  #     X-LIBRECHAT_USER_OPENIDID: "{{LIBRECHAT_USER_OPENIDID}}"
  #     X-LIBRECHAT_USER_USERNAME: "{{LIBRECHAT_USER_USERNAME}}"
  #   serverInstructions: |
  #     When sending emails:
  #     - Always confirm the message to be sent, who the sender email is, and the email address the email is being sent to

# # Balance settings
# balance:
#   enabled: false                # Enable token credit balances for users
#   startBalance: 5000000          # Initial tokens credited upon registration
#   autoRefillEnabled: true     # Enable automatic token refills
#   refillIntervalValue: 30      # Numerical value for refill interval
#   refillIntervalUnit: "days"   # Time unit for refill interval (days, hours, etc.)
#   refillAmount: 1000000          # Tokens added during each refill

speech:
  speechTab:
    conversationMode: true
    advancedMode: false
    speechToText:
      engineSTT: "external"
      languageSTT: "English (US)"
      autoTranscribeAudio: true
      decibelValue: -45
      autoSendText: 0
    textToSpeech:
      engineTTS: "external"
      voice: "alloy"
      languageTTS: "en"
      automaticPlayback: true
      playbackRate: 1.0
      cacheTTS: true

  stt:
    openai:
      url: "https://litellm.amendllc.com/v1/audio/transcriptions"
      model: "azure/whisper"
      apiKey: "${LITELLM_WHISPER_KEY}"

  tts:
    openai:
      url: "https://litellm.amendllc.com/v1/audio/speech"
      apiKey: "${LITELLM_WHISPER_KEY}"
      model: "azure/tts"
      voices: ['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']